{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def grad_U(Ui, Yij, Vj, ai, bj, reg, eta, mu):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * (reg * Ui - Vj*((Yij - (mu + np.dot(Ui, Vj) + ai + bj))))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, ai, bj, reg, eta, mu):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * (reg * Vj - Ui*((Yij - (mu + np.dot(Ui, Vj) + ai + bj))))\n",
    "\n",
    "def grad_a(Ui, Yij, Vj, ai,bj, reg, eta, mu):\n",
    "    \"\"\"Calculate the bias term for U\"\"\"\n",
    "    return eta * (reg * ai - (Yij - (mu + np.dot(Ui, Vj) + ai + bj)))\n",
    "\n",
    "def grad_b(Ui, Yij, Vj, ai, bj, reg, eta, mu):\n",
    "    \"\"\"Calculate the bias term for V\"\"\"\n",
    "    return eta * (reg * bj - (Yij - (mu + np.dot(Ui, Vj) + ai + bj)))\n",
    "\n",
    "def get_err(U, V, Y, a, b, mu, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for (user, movie, rating) in Y:\n",
    "        err = (rating - (mu + np.dot(U[user - 1], V[movie - 1]) + a[user - 1] + b[movie - 1]))**2\n",
    "        errors.append(err)\n",
    "    return  np.sqrt(sum(errors))/len(Y)\n",
    "\n",
    "    \n",
    "def train_model_with_bias(M, N, K, eta, reg, mu,  Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the U and V matrices to random\n",
    "    # values in [-0.5, 0.5]\n",
    "    U = np.random.rand(M, K) - 0.5\n",
    "    V = np.random.rand(N, K) - 0.5\n",
    "    \n",
    "    # Have one ai for every user, and one vj for every movie\n",
    "    a = np.random.rand(M, 1) - 0.5\n",
    "    b = np.random.rand(N, 1) - 0.5\n",
    "    \n",
    "    delta_01 = None\n",
    "    delta = None\n",
    "    n = 0\n",
    "    prev_loss = get_err(U, V, Y, a, b, mu, reg)\n",
    "    \n",
    "    print(prev_loss)\n",
    "    # Run for input number of epochs\n",
    "    while n < max_epochs:\n",
    "        # Implement early stopping\n",
    "        if delta_01 != None and delta != None and delta < eps * delta_01:\n",
    "            break\n",
    "        # Shuffle X and Y in order to add stochasticity\n",
    "        p = np.random.permutation(len(Y))\n",
    "        Y = Y[p]\n",
    "        # In each epoch, iterate through all the points and\n",
    "        # update the U and V vectors\n",
    "        # Need to update the U and V simultaneously, so need to create a temp variable.\n",
    "        for (user, movie, rating) in Y:\n",
    "            gradu = grad_U(U[user - 1], rating, V[movie - 1], a[user - 1], b[movie - 1], reg, eta, mu)\n",
    "            gradv = grad_V(V[movie - 1], rating, U[user - 1], a[user - 1], b[movie - 1], reg, eta, mu)\n",
    "            grada = grad_a(U[user - 1], rating, V[movie - 1], a[user - 1], b[movie - 1], reg, eta, mu)\n",
    "            gradb = grad_b(U[user - 1], rating, V[movie - 1], a[user - 1], b[movie - 1], reg, eta, mu)         \n",
    "            U[user - 1] = U[user - 1] - gradu\n",
    "            V[movie - 1] = V[movie - 1] - gradv\n",
    "            a[user - 1] = a[user -1] - grada\n",
    "            b[movie - 1] = b[movie -1] - gradb             \n",
    "        if n == 0:\n",
    "            curr_loss = get_err(U, V,Y, a, b, mu, reg)\n",
    "            delta_01 = prev_loss - curr_loss\n",
    "            prev_loss = curr_loss\n",
    "        else:\n",
    "            curr_loss = get_err(U, V,Y, a, b, mu, reg)\n",
    "            print(curr_loss)\n",
    "            delta = prev_loss - curr_loss\n",
    "            prev_loss = curr_loss\n",
    "        n += 1\n",
    "    print(n)\n",
    "    final_mse = get_err(U, V, Y, a,b, mu)\n",
    "    return (U, V, a, b, final_mse)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('um/all.dta').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,    185,   2160,      1],\n",
       "       [     1,    490,   2160,      4],\n",
       "       [     1,   1811,   2160,      3],\n",
       "       ...,\n",
       "       [458293,  17567,   1796,      1],\n",
       "       [458293,  17604,   1745,      3],\n",
       "       [458293,  17689,   1715,      3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.loadtxt('um/all.idx').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probe = []\n",
    "y_base = []\n",
    "y_valid = []\n",
    "y_hidden = []\n",
    "y_qual = []\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    if idx == 1:\n",
    "        y_base.append(train[i])\n",
    "    elif idx == 2:\n",
    "        y_valid.append(train[i])\n",
    "    elif idx == 3:\n",
    "        y_hidden.append(train[i])\n",
    "    elif idx == 4:\n",
    "        y_probe.append(train[i])\n",
    "    else:\n",
    "        y_qual.append(train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = max(train[:,0]).astype(int) # users\n",
    "N = max(train[:,1]).astype(int) # movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with  458293  users,  17770  movies.\n",
      "[0.00012161]\n",
      "[9.35081998e-05]\n",
      "[9.30461058e-05]\n",
      "[9.27270261e-05]\n",
      "[9.27330291e-05]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "k = 20\n",
    "reg = 0.1\n",
    "eta = 0.1 # learning rate\n",
    "mu = np.mean(np.array(y_base + y_valid + y_hidden + y_probe)[:, 3])\n",
    "U, V, a, b, rmse = train_model_with_bias(M, N, k, eta, reg, mu, np.array(y_base + y_valid + y_hidden + y_probe)[:, [0, 1, 3]])\n",
    "V = V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26694572,  0.18593633, -0.21908995, ..., -0.09893097,\n",
       "         0.35584393, -0.12157863],\n",
       "       [-0.09354178, -0.10360051, -0.01521018, ...,  0.03355135,\n",
       "        -0.39683215, -0.19730886],\n",
       "       [-0.09140521, -0.12679148,  0.14712753, ...,  0.14465797,\n",
       "         0.28422754,  0.09028438],\n",
       "       ...,\n",
       "       [-0.03010121, -0.01638623, -0.10615417, ...,  0.03665387,\n",
       "        -0.14651433,  0.03237452],\n",
       "       [-0.00122643,  0.09361242, -0.09224936, ...,  0.04259903,\n",
       "         0.01005817, -0.11262746],\n",
       "       [-0.04548208, -0.11773063,  0.16672062, ..., -0.06638057,\n",
       "        -0.05651275,  0.00096565]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is  [0.00081946]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test error is \", get_err(U, V.T,np.array(y_probe)[:, [0, 1, 3]], a, b, mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for (user, movie, rating) in np.array(y_qual)[:, [0, 1, 3]]:\n",
    "    test_preds.append((mu + np.dot(U[user - 1], V.T[movie - 1]) + a[user - 1] + b[movie - 1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749898"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_preds2.txt', 'w') as f:\n",
    "    for item in test_preds:\n",
    "        f.write(\"%.4f\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
