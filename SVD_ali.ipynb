{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def grad_U(Ui, Yij, Vj, ai, bj, reg, eta, mu):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * (reg * Ui - Vj*((Yij - (mu + np.dot(Ui, Vj) + ai + bj))))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, ai, bj, reg, eta, mu):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * (reg * Vj - Ui*((Yij - (mu + np.dot(Ui, Vj) + ai + bj))))\n",
    "\n",
    "def grad_a(Ui, Yij, Vj, ai,bj, reg, eta, mu):\n",
    "    \"\"\"Calculate the bias term for U\"\"\"\n",
    "    return eta * (reg * ai - (Yij - (mu + np.dot(Ui, Vj) + ai + bj)))\n",
    "\n",
    "def grad_b(Ui, Yij, Vj, ai, bj, reg, eta, mu):\n",
    "    \"\"\"Calculate the bias term for V\"\"\"\n",
    "    return eta * (reg * bj - (Yij - (mu + np.dot(Ui, Vj) + ai + bj)))\n",
    "\n",
    "def get_err(U, V, Y, a, b, mu, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for (user, movie, rating) in Y:\n",
    "        err = (rating - (mu + np.dot(U[user - 1], V[movie - 1]) + a[user - 1] + b[movie - 1]))**2\n",
    "        errors.append(err)\n",
    "    return  np.sqrt(sum(errors))/len(Y)\n",
    "\n",
    "    \n",
    "def train_model_with_bias(M, N, K, eta, reg, mu,  Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the U and V matrices to random\n",
    "    # values in [-0.5, 0.5]\n",
    "    U = np.random.rand(M, K) - 0.5\n",
    "    V = np.random.rand(N, K) - 0.5\n",
    "    \n",
    "    # Have one ai for every user, and one vj for every movie\n",
    "    a = np.random.rand(M, 1) - 0.5\n",
    "    b = np.random.rand(N, 1) - 0.5\n",
    "    \n",
    "    delta_01 = None\n",
    "    delta = None\n",
    "    n = 0\n",
    "    prev_loss = get_err(U, V, Y, a, b, mu, reg)\n",
    "    \n",
    "    print(prev_loss)\n",
    "    # Run for input number of epochs\n",
    "    while n < max_epochs:\n",
    "        # Implement early stopping\n",
    "        if delta_01 != None and delta != None and delta < eps * delta_01:\n",
    "            break\n",
    "        # Shuffle X and Y in order to add stochasticity\n",
    "        p = np.random.permutation(len(Y))\n",
    "        Y = Y[p]\n",
    "        # In each epoch, iterate through all the points and\n",
    "        # update the U and V vectors\n",
    "        # Need to update the U and V simultaneously, so need to create a temp variable.\n",
    "        for (user, movie, rating) in Y:\n",
    "            gradu = grad_U(U[user - 1], rating, V[movie - 1], a[user - 1], b[movie - 1], reg, eta, mu)\n",
    "            gradv = grad_V(V[movie - 1], rating, U[user - 1], a[user - 1], b[movie - 1], reg, eta, mu)\n",
    "            grada = grad_a(U[user - 1], rating, V[movie - 1], a[user - 1], b[movie - 1], reg, eta, mu)\n",
    "            gradb = grad_b(U[user - 1], rating, V[movie - 1], a[user - 1], b[movie - 1], reg, eta, mu)         \n",
    "            U[user - 1] = U[user - 1] - gradu\n",
    "            V[movie - 1] = V[movie - 1] - gradv\n",
    "            a[user - 1] = a[user -1] - grada\n",
    "            b[movie - 1] = b[movie -1] - gradb             \n",
    "        if n == 0:\n",
    "            curr_loss = get_err(U, V,Y, a, b, mu, reg)\n",
    "            delta_01 = prev_loss - curr_loss\n",
    "            prev_loss = curr_loss\n",
    "        else:\n",
    "            curr_loss = get_err(U, V,Y, a, b, mu, reg)\n",
    "            print(curr_loss)\n",
    "            delta = prev_loss - curr_loss\n",
    "            prev_loss = curr_loss\n",
    "        n += 1\n",
    "    print(n)\n",
    "    final_mse = get_err(U, V, Y, a,b, mu)\n",
    "    return (U, V, a, b, final_mse)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rahil's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    eta (the learning rate), ai (ith element of a), bj (jth element of b)\n",
    "    and mu (average rating).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * ((reg * Ui) - Vj * (Yij - mu - np.dot(Ui, Vj) - ai - bj))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta, ai, bj, mu):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    eta (the learning rate), ai (ith element of a), bj (jth element of b)\n",
    "    and mu (average rating).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * ((reg * Vj) - Ui * (Yij - mu - np.dot(Ui, Vj) - ai - bj))\n",
    "\n",
    "def grad_a(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    eta (the learning rate), ai (ith element of a), bj (jth element of b)\n",
    "    and mu (average rating).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to ai multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * ((reg * ai) - (Yij - mu - np.dot(Ui, Vj) - ai - bj))\n",
    "\n",
    "def grad_b(Ui, Yij, Vj, reg, eta, ai, bj, mu):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    eta (the learning rate), ai (ith element of a), bj (jth element of b)\n",
    "    and mu (average rating).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to bj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return eta * ((reg * bj) - (Yij - mu - np.dot(Ui, Vj) - ai - bj))\n",
    "\n",
    "def get_err(U, V, Y, a, b, mu, reg=0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j,\n",
    "    user/movie matrices U and V, user/movie vectors a and b and average rating mu.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "\n",
    "    reg_err = (reg/2) * (np.linalg.norm(U) ** 2 + np.linalg.norm(V) ** 2 +\n",
    "                         np.linalg.norm(a) ** 2 + np.linalg.norm(b) ** 2)\n",
    "    loss_err = 0\n",
    "    for point in Y:\n",
    "        i, j, y = point\n",
    "        loss_err += (y - mu - np.dot(U[i - 1], V[j - 1]) - a[i - 1] - b[j - 1]) ** 2\n",
    "    return ((reg_err + (1/2) * loss_err)/len(Y))\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, mu, eps=0.0001, max_epochs=30):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V and M x 1 vector a and N x 1 vector b\n",
    "    such that rating Y_ij is approximated by (UV^T)_ij + a_i + b_j + mu.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, a, b, err) consisting of U, V, a, b and the\n",
    "    unregularized MSE of the model.\n",
    "    \"\"\"\n",
    "    # Randomly initialize U, V, a and b.\n",
    "    U = np.random.uniform(-0.5, 0.5, (M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, (N, K))\n",
    "    a = np.random.uniform(-0.5, 0.5, (M, ))\n",
    "    b = np.random.uniform(-0.5, 0.5, (N, ))\n",
    "    # Find the initial loss.\n",
    "    prev_err = get_err(U, V, Y, a, b, mu, reg)\n",
    "    for epoch in range(max_epochs):\n",
    "        np.random.shuffle(Y)\n",
    "        for point in Y:\n",
    "            # Update the rows of U and V and elements of a and b.\n",
    "            i, j, y = point\n",
    "            del_U = grad_U(U[i - 1], y, V[j - 1], reg, eta, a[i - 1], b[j - 1], mu)\n",
    "            del_V = grad_V(V[j - 1], y, U[i - 1], reg, eta, a[i - 1], b[j - 1], mu)\n",
    "            del_a = grad_a(U[i - 1], y, V[j - 1], reg, eta, a[i - 1], b[j - 1], mu)\n",
    "            del_b = grad_b(U[i - 1], y, V[j - 1], reg, eta, a[i - 1], b[j - 1], mu)\n",
    "            U[i - 1] = U[i - 1] - del_U\n",
    "            V[j - 1] = V[j - 1] - del_V\n",
    "            a[i - 1] = a[i - 1] - del_a\n",
    "            b[j - 1] = b[j - 1] - del_b\n",
    "        err = get_err(U, V, Y, a, b, mu, reg)\n",
    "        diff = prev_err - err\n",
    "        if epoch == 0:\n",
    "            # Compute the initial loss reduction.\n",
    "            tol = diff\n",
    "        else:\n",
    "            # Check if loss reduction is too small.\n",
    "            if diff/tol <= eps:\n",
    "                return(U, V, a, b, get_err(U, V, Y, a, b, mu))\n",
    "        prev_err = err\n",
    "        print(err)\n",
    "    return(U, V, a, b, np.sqrt(get_err(U, V, Y, a , b, mu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('um/all.dta').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,    185,   2160,      1],\n",
       "       [     1,    490,   2160,      4],\n",
       "       [     1,   1811,   2160,      3],\n",
       "       ...,\n",
       "       [458293,  17567,   1796,      1],\n",
       "       [458293,  17604,   1745,      3],\n",
       "       [458293,  17689,   1715,      3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e96d835427c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'um/all.idx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/myenvir/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/myenvir/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "indices = np.loadtxt('um/all.idx').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probe = []\n",
    "y_base = []\n",
    "y_valid = []\n",
    "y_hidden = []\n",
    "y_qual = []\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    if idx == 1:\n",
    "        y_base.append(train[i])\n",
    "    elif idx == 2:\n",
    "        y_valid.append(train[i])\n",
    "    elif idx == 3:\n",
    "        y_hidden.append(train[i])\n",
    "    elif idx == 4:\n",
    "        y_probe.append(train[i])\n",
    "    else:\n",
    "        y_qual.append(train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = max(train[:,0]).astype(int) # users\n",
    "N = max(train[:,1]).astype(int) # movies\n",
    "\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e963cffc9131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# point : (user number)       (movie number)       (date number)       (rating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_base\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0muser_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_base' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "num_users = 458293\n",
    "user_time = [None] * (num_users + 1)\n",
    "user_bias = [None] * (num_users + 1)\n",
    "\n",
    "# point : (user number)       (movie number)       (date number)       (rating)\n",
    "for point in y_base:\n",
    "    user_num = point[0]\n",
    "    rating = point[3]\n",
    "    time = point[2]\n",
    "    \n",
    "    user_time[user_num].append([rating, time])\n",
    "\n",
    "for user in user_time:\n",
    "    if user != None:            \n",
    "        X = user_time[user][:,0]\n",
    "        y = user_time[user][:,1]\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        user_bias.append(reg.coef_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# for movie-rating hi my name is ally boobs! \n",
    "\n",
    "num_movies = 17770\n",
    "movie_time = [None] * (num_users + 1)\n",
    "movie_bias = [None] * (num_users + 1)\n",
    "\n",
    "# point : (user number)       (movie number)       (date number)       (rating)\n",
    "for point in y_base:\n",
    "    movie_num = point[0]\n",
    "    rating = point[3]\n",
    "    time = point[2]\n",
    "    \n",
    "    movie_time[user_num].append([rating, time])\n",
    "\n",
    "for user in user_time:\n",
    "    if user != None:            \n",
    "        X = movie_time[user][:,0]\n",
    "        y = movie_time[user][:,1]\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        movie_bias.append(reg.coef_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with  458293  users,  17770  movies.\n",
      "0.4383475123973069\n",
      "0.43347664091109556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-35646e38f281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#U, V, a, b, rmse = train_model_with_bias(M, N, k, eta, reg, mu, np.array(y_base + y_valid + y_hidden + y_probe)[:, [0, 1, 3]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b676190f254d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(M, N, K, eta, reg, Y, mu, eps, max_epochs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mdel_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mdel_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mdel_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdel_U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdel_V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "k = 20\n",
    "reg = 0.1\n",
    "eta = 0.1 # learning rate\n",
    "mu = np.mean(np.array(y_base + y_valid + y_hidden)[:, 3])\n",
    "#U, V, a, b, rmse = train_model_with_bias(M, N, k, eta, reg, mu, np.array(y_base + y_valid + y_hidden + y_probe)[:, [0, 1, 3]])\n",
    "U, V, a, b, rmse = train_model(M, N, k, eta, reg, np.array(y_base + y_valid + y_hidden)[:, [0, 1, 3]], mu)\n",
    "\n",
    "V = V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is  [0.00081946]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test error is \", get_err(U, V.T,np.array(y_probe)[:, [0, 1, 3]], a, b, mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for (user, movie, rating) in np.array(y_qual)[:, [0, 1, 3]]:\n",
    "    test_preds.append((mu + np.dot(U[user - 1], V.T[movie - 1]) + a[user - 1] + b[movie - 1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749898"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_preds2.txt', 'w') as f:\n",
    "    for item in test_preds:\n",
    "        f.write(\"%.4f\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
